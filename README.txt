FEXCO DevOps Take-Home Assessment

Objective
Provision an Azure Kubernetes Service (AKS) cluster using Terraform, deploy a simple Helm workload to it, and manage the lifecycle using a GitHub Actions CI/CD pipeline.

##########################
Prerequisites 

- Terraform CLI
- GitHub CLI
- Azure CLI 
- kubectl 
- Code Editor (Visual Studio)

Accounts for
- github
- Azure

Versions Used
- Terraform v1.13.4
- git version 2.50.1
- azure-cli 2.78.0
- kubectl v1.34.1

CLI login

azure
az login

Kubernetes 
# Get AKS cluster credentials (admin context)
az aks get-credentials \
  --resource-group <RESOURCE_GROUP> \
  --name <CLUSTER_NAME> \
  --admin

##########################
Azure Requirements:

- Azure subscription with rights to create resource groups, AKS, and networking
- Service Principal or OIDC setup for authentication in GitHub Actions
- Storage account and container for Terraform remote backend (configured in backend.tf)

##########################
File definition

main.tf
Core infrastructure definition — includes creation of the Azure Resource Group, AKS cluster, and Helm deployment (Grafana).
This file represents the primary deployment flow.

providers.tf
Declares all Terraform providers used (AzureRM, Kubernetes, Helm).
Configures authentication, cluster connections, and provider aliases.

backend.tf
Defines the Terraform backend configuration (e.g., remote state stored in Azure Storage).
Ensures state consistency across runs and CI/CD.

variables.tf
Contains input variables such as resource group name, location, cluster name, and other configurable parameters used across .tf files.

outputs.tf
Exports key values after deployment (e.g., cluster name, kubeconfig, resource group).
Useful for debugging or chaining modules.

monitor.tf
Deploys monitoring components — Log Analytics Workspace, metrics, and alerts associated with the AKS cluster.
Enables observability of workloads.

net-policy.tf
Defines the Kubernetes Network Policy (allowing only HTTP traffic on port 80).
Demonstrates baseline cluster network segmentation.

helm/
Directory containing Helm-related configuration.
Typically includes a values.yaml file specifying Helm chart parameters such as service type, load balancer, and persistence settings.

.gitignore
Excludes sensitive or autogenerated files from version control (for example: kubeconfig_aks.yaml, .terraform/, terraform.tfstate*).
Prevents accidental commits of secrets or local artifacts.

.github/workflows/terraform.yml
GitHub Actions workflow file defining your Terraform CI/CD pipeline.
Automates plan, apply, and destroy stages against Azure, with environment approvals.

.github/pull_request_template.md
Pull Request template used to standardize PR descriptions.
Ensures each change includes context, testing notes, and review checklists.

##########################
Setup Steps and How to Trigger the Pipeline

1. Clone the repository:
   git clone https://https://github.com/cpelayo/fexco-devops
   cd <path/fexco-devops>

2. Set GitHub Secrets:
   ARM_CLIENT_ID
   ARM_CLIENT_SECRET
   ARM_TENANT_ID
   ARM_SUBSCRIPTION_ID

3. Pipeline Triggers:
   - Runs automatically on each push to the master branch.
   - Can be triggered manually in the Actions tab -> Terraform CI/CD -> Run workflow.
   - Triggers when a PR is created.

4. Pipeline Stages:
   - Lint & Validate: Runs terraform fmt and terraform validate.
   - Plan: Generates and uploads a Terraform plan as an artifact.
   - Apply: Requires manual approval; applies infrastructure.
   - Destroy: Requires manual approval; stage to clean up all resources.

##########################

How to Verify the Deployed Workload
1. Retrieve AKS credentials:
az aks get-credentials \
  --resource-group aks-demo-rg \
  --name aks-demo-cluster \
  --admin

2. List pods:
   kubectl get pods -A

3. Check LoadBalancer service:
   kubectl get svc

   Example output:
   NAME         TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)        AGE
   nginx        LoadBalancer   10.0.123.45    20.12.34.56     80:31000/TCP   2m

4. Open the EXTERNAL-IP in your browser to verify the workload.

##########################
Teardown Instructions

1. Go to GitHub Actions -> Terraform CI/CD
2. Select the same run that applied the plan
3. Confirm manual approval in Review Deployments; check on production and approve and deploy.

##########################
Network Policy test

Connect to kubernetes cluster
az aks get-credentials \
  --resource-group aks-demo-rg \
  --name aks-demo-cluster \
  --admin

Create test POD, port different to 80
kubectl run test-server --image=python:3.9-slim --restart=Never \
--port=5678 \
--command -- python -m http.server 5678

get test pod IP and grafana ID
kubectl get pod  -o wide

connect to grafana POD to test from there
kubectl exec -it grafana-<ID> -- sh

then run a curl
curl -v http://<test-server>

IT SHOULD TIME OUT!!

Delete NW Policy
kubectl delete networkpolicy allow-http-only -n default

connect to grafana again to test w/o policy
kubectl exec -it grafana-<ID> -- sh

run curl again
curl -v http://<test-server>

*   Trying 10.224.0.24:5678...
* Connected to 10.224.0.24 (10.224.0.24) port 5678
* using HTTP/1.x
....

Network policy will be created in the next apply

##########################
Design Trade-offs and Shortcuts Taken

- Used Service Principal instead of OIDC to simplify configuration.
- Single-node AKS cluster to reduce cost and complexity.
- Simple Helm chart (grafana) to focus on CI/CD integration.
- Azure remote terraform backend for consistent state management.
- No private registry or TLS cert manager (optional stretch goal).
- Configured a simple CPU alert to AKS node.
- Comfigured a simple Network Policy.

Future Improvements (Optional Stretch Goals)
- Add TLS with self-signed certificates for ingress.
- Add observability with Prometheus and Grafana.
- Add multi-environment structure (dev, stage, prod) using Terraform workspaces.
